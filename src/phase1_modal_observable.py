"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NATURE INSPIRED COMPUTATION - PHASE 1
Production-Ready Implementation with Comprehensive Observability

HIGH-LEVEL ARCHITECTURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MODAL.COM CLOUD EXECUTION                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  H100 GPU     â”‚â†’â”‚  TensorFlow  â”‚â†’â”‚  Checkpoint System (Modal Volume)â”‚  â”‚
â”‚  â”‚  80GB VRAM    â”‚  â”‚  CUDA 12.x   â”‚  â”‚  Persistent Storage            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DATA FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Kaggle API â†’ Sentiment140 (1.6M) â†’ Sample (15K) â†’ Preprocess â†’ Cache
                                                           â†“
                                                    BiLSTM Model
                                                           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OPTIMIZATION PIPELINE (6 Metaheuristics + DOE)              â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  1. DOE (Taguchi L9)  â†’ Systematic Exploration              â”‚
    â”‚  2. PSO               â†’ Swarm Intelligence                   â”‚
    â”‚  3. Tabu Search       â†’ Memory-Based Local Search           â”‚
    â”‚  4. Grey Wolf (GWO)   â†’ Pack Hunting Simulation            â”‚
    â”‚  5. Whale (WOA)       â†’ Bubble-net Feeding                  â”‚
    â”‚  6. Diff. Evol. (DE)  â†’ Mutation & Crossover               â”‚
    â”‚  7. Sim. Anneal. (SA) â†’ Thermal Annealing Process          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    Save Checkpoints â†’ Resume on Failure

CHECKPOINT STRATEGY:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/checkpoints/
â”œâ”€â”€ preprocessed_data.npz        # 15MB - Reusable across runs
â”œâ”€â”€ baseline_checkpoint.json      # Model performance baseline
â”œâ”€â”€ DOE_checkpoint.json          # Design of Experiments results
â”œâ”€â”€ PSO_checkpoint.json          # Particle Swarm results
â”œâ”€â”€ TabuSearch_checkpoint.json   # Tabu Search results
â”œâ”€â”€ GWO_checkpoint.json          # Grey Wolf results
â”œâ”€â”€ WOA_checkpoint.json          # Whale Optimization results
â”œâ”€â”€ DE_checkpoint.json           # Differential Evolution results
â”œâ”€â”€ SA_checkpoint.json           # Simulated Annealing results
â””â”€â”€ phase1_results.json          # Cumulative results

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import modal
import os
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 1: MODAL CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = modal.App("nic-phase1-production")

image = (
    modal.Image
    .from_registry("tensorflow/tensorflow:latest-gpu")
    .apt_install("unzip", "wget")
    .pip_install(
        "pandas",
        "scikit-learn",
        "nltk",
        "tqdm",
        "matplotlib",
        "seaborn",
        "kaggle"
    )
)

volume = modal.Volume.from_name("nic-checkpoints", create_if_missing=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 2: DATA STRUCTURES & TYPE DEFINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AlgorithmResult:
    """Structured result from a single optimization algorithm."""
    algorithm_name: str
    best_accuracy: float
    best_lstm_units: int
    best_dropout: float
    best_learning_rate: float
    execution_time_seconds: float
    iterations_completed: int
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class HyperparameterConfig:
    """BiLSTM model hyperparameters."""
    lstm_units: int
    dropout_rate: float
    learning_rate: float
    
    def __repr__(self) -> str:
        return f"LSTM={self.lstm_units}, Drop={self.dropout_rate:.3f}, LR={self.learning_rate:.6f}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 3: LOGGING CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_logger(name: str = "NIC") -> logging.Logger:
    """Configure structured logging with timestamps."""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    if logger.handlers:
        return logger
    
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    return logger


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 4: CHECKPOINT MANAGEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CheckpointManager:
    """Handles persistent storage and retrieval of training state."""
    
    def __init__(self, checkpoint_dir: Path, logger: logging.Logger):
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger
        
    def save_checkpoint(
        self,
        algorithm_name: str,
        data: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """Atomically save checkpoint to persistent storage."""
        try:
            checkpoint_file = self.checkpoint_dir / f"{algorithm_name}_checkpoint.json"
            
            full_data = {
                "algorithm": algorithm_name,
                "timestamp": datetime.now().isoformat(),
                "data": data,
                "metadata": metadata or {}
            }
            
            temp_file = checkpoint_file.with_suffix('.tmp')
            with open(temp_file, 'w') as f:
                json.dump(full_data, f, indent=2)
            
            temp_file.replace(checkpoint_file)
            
            self.logger.info(f"âœ… Checkpoint saved: {checkpoint_file.name}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to save checkpoint for {algorithm_name}: {e}")
            return False
    
    def load_checkpoint(self, algorithm_name: str) -> Optional[Dict[str, Any]]:
        """Load checkpoint if exists, otherwise return None."""
        checkpoint_file = self.checkpoint_dir / f"{algorithm_name}_checkpoint.json"
        
        if not checkpoint_file.exists():
            self.logger.debug(f"No checkpoint found for {algorithm_name}")
            return None
        
        try:
            with open(checkpoint_file, 'r') as f:
                full_data = json.load(f)
            
            self.logger.info(f"âœ… Loaded checkpoint for {algorithm_name}")
            return full_data['data']
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to load checkpoint for {algorithm_name}: {e}")
            return None
    
    def checkpoint_exists(self, algorithm_name: str) -> bool:
        """Fast check for checkpoint existence."""
        return (self.checkpoint_dir / f"{algorithm_name}_checkpoint.json").exists()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 5: MODAL FUNCTION - MAIN TRAINING PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.function(
    image=image,
    gpu="H100",
    timeout=7200,
    secrets=[modal.Secret.from_name("kaggle-secret")],
    volumes={"/checkpoints": volume}
)
def run_phase1_training() -> Dict[str, Any]:
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    MAIN TRAINING PIPELINE - PHASE 1
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    
    import pandas as pd
    import numpy as np
    import re
    import nltk
    import traceback
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import WordNetLemmatizer
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout
    from tensorflow.keras.preprocessing.text import Tokenizer
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    
    logger = setup_logger("NIC-Phase1")
    logger.info("="*70)
    logger.info("PHASE 1 TRAINING PIPELINE STARTED")
    logger.info("="*70)
    
    checkpoint_dir = Path("/checkpoints")
    checkpoint_mgr = CheckpointManager(checkpoint_dir, logger)
    
    gpus = tf.config.list_physical_devices('GPU')
    logger.info(f"GPUs Available: {len(gpus)}")
    if gpus:
        for gpu in gpus:
            logger.info(f"  â””â”€ {gpu.name} ({gpu.device_type})")
    else:
        logger.warning("âš ï¸ No GPU detected - training will be slow!")
    
    logger.info("Downloading NLTK data...")
    for pkg in ['stopwords', 'punkt', 'punkt_tab', 'wordnet']:
        try:
            nltk.download(pkg, quiet=True)
        except Exception as e:
            logger.warning(f"Failed to download {pkg}: {e}")
    
    results_list: List[AlgorithmResult] = []
    
    try:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.2: DATA LOADING & PREPROCESSING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.2: DATA PIPELINE")
        logger.info("â”€"*70)
        
        preprocessed_file = checkpoint_dir / "preprocessed_data.npz"
        
        if preprocessed_file.exists():
            logger.info("âœ… Loading cached preprocessed data...")
            start_time = time.time()
            
            data = np.load(preprocessed_file, allow_pickle=True)
            X_train_seq = data['X_train_seq']
            X_val_seq = data['X_val_seq']
            X_test_seq = data['X_test_seq']
            y_train_arr = data['y_train_arr']
            y_val_arr = data['y_val_arr']
            y_test_arr = data['y_test_arr']
            
            load_time = time.time() - start_time
            logger.info(f"  â””â”€ Loaded in {load_time:.2f}s")
            logger.info(f"  â””â”€ Train: {len(X_train_seq)} | Val: {len(X_val_seq)} | Test: {len(X_test_seq)}")
            
        else:
            logger.info("ğŸ“¥ No cached data found - downloading and preprocessing...")
            
            kaggle_username = os.getenv("KAGGLE_USERNAME")
            kaggle_key = os.getenv("KAGGLE_KEY")
            
            if not kaggle_username or not kaggle_key:
                raise ValueError("ERROR: Kaggle credentials not found in Modal secrets!")
            
            os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
            with open(os.path.expanduser("~/.kaggle/kaggle.json"), 'w') as f:
                json.dump({"username": kaggle_username, "key": kaggle_key}, f)
            os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)
            
            logger.info("âœ… Kaggle credentials configured")
            
            logger.info("Downloading Sentiment140 dataset...")
            download_start = time.time()
            os.system("kaggle datasets download -d kazanova/sentiment140 -p /tmp --force 2>&1")
            os.system("unzip -o /tmp/sentiment140.zip -d /tmp/ 2>&1")
            download_time = time.time() - download_start
            logger.info(f"  â””â”€ Downloaded in {download_time:.2f}s")
            
            COL_NAMES = ['target', 'ids', 'date', 'flag', 'user', 'text']
            logger.info("Loading CSV...")
            df = pd.read_csv(
                '/tmp/training.1600000.processed.noemoticon.csv',
                encoding='ISO-8859-1',
                names=COL_NAMES
            )
            
            original_size = len(df)
            df = df.drop_duplicates(subset=['text', 'target'], keep='first')
            logger.info(f"  â””â”€ Removed {original_size - len(df)} duplicates")
            
            SAMPLE_SIZE = 15000
            df = df.sample(n=SAMPLE_SIZE, random_state=42)
            logger.info(f"  â””â”€ Sampled {SAMPLE_SIZE} records")
            
            logger.info("Preprocessing text...")
            preprocess_start = time.time()
            
            def basic_text_cleaning(text: str) -> str:
                text = text.lower()
                text = re.sub(r'https?://\S+', '', text)
                text = re.sub(r'@[^\s]+', '', text)
                text = re.sub(r'#', '', text)
                text = re.sub(r'[^a-z\s]', '', text)
                text = re.sub(r'\s+', ' ', text).strip()
                return text
            
            df['text_cleaned'] = df['text'].apply(basic_text_cleaning)
            
            stop_words = set(stopwords.words('english'))
            lemmatizer = WordNetLemmatizer()
            
            def tokenize_lemmatize(text: str) -> str:
                if not isinstance(text, str):
                    return ""
                tokens = word_tokenize(text)
                lemmas = [
                    lemmatizer.lemmatize(tok)
                    for tok in tokens
                    if tok not in stop_words and len(tok) > 2
                ]
                return ' '.join(lemmas)
            
            df['text_final'] = df['text_cleaned'].apply(tokenize_lemmatize)
            df['target_encoded'] = df['target'].replace(4, 1)
            df = df[df['text_final'] != '']
            
            preprocess_time = time.time() - preprocess_start
            logger.info(f"  â””â”€ Preprocessed in {preprocess_time:.2f}s")
            
            X = df['text_final']
            y = df['target_encoded']
            X_train, X_temp, y_train, y_temp = train_test_split(
                X, y, test_size=0.3, random_state=42, stratify=y
            )
            X_val, X_test, y_val, y_test = train_test_split(
                X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
            )
            
            logger.info(f"  â””â”€ Split: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")
            
            MAX_WORDS = 5000
            MAX_LEN = 50
            
            logger.info(f"Tokenizing sequences (max_words={MAX_WORDS}, max_len={MAX_LEN})...")
            tokenizer_nn = Tokenizer(num_words=MAX_WORDS, oov_token="<OOV>")
            tokenizer_nn.fit_on_texts(X_train)
            
            X_train_seq = pad_sequences(tokenizer_nn.texts_to_sequences(X_train), maxlen=MAX_LEN)
            X_val_seq = pad_sequences(tokenizer_nn.texts_to_sequences(X_val), maxlen=MAX_LEN)
            X_test_seq = pad_sequences(tokenizer_nn.texts_to_sequences(X_test), maxlen=MAX_LEN)
            
            y_train_arr = y_train.values
            y_val_arr = y_val.values
            y_test_arr = y_test.values
            
            logger.info("Caching preprocessed data...")
            np.savez_compressed(
                preprocessed_file,
                X_train_seq=X_train_seq,
                X_val_seq=X_val_seq,
                X_test_seq=X_test_seq,
                y_train_arr=y_train_arr,
                y_val_arr=y_val_arr,
                y_test_arr=y_test_arr
            )
            logger.info(f"âœ… Cached to {preprocessed_file}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.3: MODEL DEFINITION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        MAX_WORDS = 5000
        MAX_LEN = 50
        
        def build_bilstm(config: HyperparameterConfig) -> tf.keras.Model:
            """Build BiLSTM model with given hyperparameters."""
            model = Sequential([
                Embedding(MAX_WORDS, 64, input_length=MAX_LEN, name="embedding"),
                Bidirectional(
                    LSTM(config.lstm_units, return_sequences=False),
                    name="bilstm"
                ),
                Dropout(config.dropout_rate, name="dropout1"),
                Dense(32, activation='relu', name="dense1"),
                Dropout(config.dropout_rate / 2, name="dropout2"),
                Dense(1, activation='sigmoid', name="output")
            ])
            
            model.compile(
                loss='binary_crossentropy',
                optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),
                metrics=['accuracy']
            )
            
            return model
        
        def fitness_function(config: HyperparameterConfig) -> float:
            """Evaluate model with given hyperparameters."""
            try:
                tf.keras.backend.clear_session()
                
                model = build_bilstm(config)
                model.fit(
                    X_train_seq, y_train_arr,
                    validation_data=(X_val_seq, y_val_arr),
                    epochs=2,
                    batch_size=64,
                    verbose=0
                )
                
                y_pred = (model.predict(X_val_seq, verbose=0) > 0.5).astype(int)
                accuracy = accuracy_score(y_val_arr, y_pred)
                
                return accuracy
                
            except Exception as e:
                logger.error(f"âš ï¸ Fitness evaluation error: {e}")
                return 0.5
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.4: BASELINE MODEL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.4: BASELINE MODEL")
        logger.info("â”€"*70)
        
        baseline_checkpoint = checkpoint_mgr.load_checkpoint("baseline")
        
        if baseline_checkpoint:
            baseline_acc = baseline_checkpoint['accuracy']
            logger.info(f"âœ… Loaded from checkpoint: {baseline_acc:.4f}")
        else:
            try:
                logger.info("Training baseline BiLSTM (3 epochs)...")
                start_time = time.time()
                
                baseline_config = HyperparameterConfig(
                    lstm_units=64,
                    dropout_rate=0.6,
                    learning_rate=0.9
                )
                
                baseline_model = build_bilstm(baseline_config)
                baseline_model.fit(
                    X_train_seq, y_train_arr,
                    validation_data=(X_val_seq, y_val_arr),
                    epochs=3,
                    batch_size=64,
                    verbose=1
                )
                
                y_pred = (baseline_model.predict(X_test_seq) > 0.5).astype(int)
                baseline_acc = accuracy_score(y_test_arr, y_pred)
                baseline_time = time.time() - start_time
                
                logger.info(f"âœ… Baseline Accuracy: {baseline_acc:.4f} ({baseline_time:.2f}s)")
                
                checkpoint_mgr.save_checkpoint(
                    "baseline",
                    {"accuracy": float(baseline_acc), "time": baseline_time}
                )
                
            except Exception as e:
                logger.error(f"âŒ Baseline training failed: {e}")
                baseline_acc = 0.75
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.5: DESIGN OF EXPERIMENTS (DOE) - TAGUCHI L9
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.5: DESIGN OF EXPERIMENTS (TAGUCHI L9)")
        logger.info("â”€"*70)
        
        doe_checkpoint = checkpoint_mgr.load_checkpoint("DOE")
        
        if doe_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**doe_checkpoint))
        else:
            try:
                logger.info("Running Taguchi L9 orthogonal array...")
                start_time = time.time()
                
                # Taguchi L9: 3 factors Ã— 3 levels
                taguchi_l9 = [

                    (128, 0.2, 0.01),
                    (128, 0.35, 0.001),
                    (128, 0.5, 0.005)
                ]
                
                best_acc = 0.0
                best_config = None
                
                for i, (lstm, drop, lr) in enumerate(taguchi_l9):
                    config = HyperparameterConfig(lstm, drop, lr)
                    logger.info(f"  DOE Run {i+1}/9: {config}")
                    
                    acc = fitness_function(config)
                    logger.info(f"    â””â”€ Accuracy: {acc:.4f}")
                    
                    if acc > best_acc:
                        best_acc = acc
                        best_config = config
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="DOE",
                    best_accuracy=float(best_acc),
                    best_lstm_units=int(best_config.lstm_units),
                    best_dropout=float(best_config.dropout_rate),
                    best_learning_rate=float(best_config.learning_rate),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=9,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… DOE Complete: Best={best_acc:.4f} @ {best_config}")
                
                checkpoint_mgr.save_checkpoint("DOE", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ DOE failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.6: PARTICLE SWARM OPTIMIZATION (PSO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.6: PARTICLE SWARM OPTIMIZATION")
        logger.info("â”€"*70)
        
        pso_checkpoint = checkpoint_mgr.load_checkpoint("PSO")
        
        if pso_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**pso_checkpoint))
        else:
            try:
                logger.info("Initializing PSO (5 particles, 3 iterations)...")
                start_time = time.time()
                
                # PSO parameters
                n_particles = 5
                n_iterations = 3
                w = 0.7  # Inertia
                c1 = 1.5  # Cognitive
                c2 = 1.5  # Social
                
                # Search bounds
                bounds = {
                    'lstm': (32, 128),
                    'dropout': (0.2, 0.5),
                    'lr': (0.001, 0.01)
                }
                
                # Initialize particles
                particles = []
                velocities = []
                pbest = []
                pbest_scores = []
                
                for _ in range(n_particles):
                    lstm = int(np.random.uniform(bounds['lstm'][0], bounds['lstm'][1]))
                    lstm = min([32, 64, 128], key=lambda x: abs(x - lstm))
                    dropout = np.random.uniform(bounds['dropout'][0], bounds['dropout'][1])
                    lr = np.random.uniform(bounds['lr'][0], bounds['lr'][1])
                    
                    particles.append([lstm, dropout, lr])
                    velocities.append([0.0, 0.0, 0.0])
                    pbest.append([lstm, dropout, lr])
                    pbest_scores.append(0.0)
                
                gbest = None
                gbest_score = 0.0
                
                # PSO iterations
                for iter_num in range(n_iterations):
                    logger.info(f"  PSO Iteration {iter_num + 1}/{n_iterations}")
                    
                    for i in range(n_particles):
                        config = HyperparameterConfig(
                            int(particles[i][0]),
                            particles[i][1],
                            particles[i][2]
                        )
                        
                        acc = fitness_function(config)
                        logger.info(f"    Particle {i+1}: {config} â†’ {acc:.4f}")
                        
                        # Update personal best
                        if acc > pbest_scores[i]:
                            pbest_scores[i] = acc
                            pbest[i] = particles[i].copy()
                        
                        # Update global best
                        if acc > gbest_score:
                            gbest_score = acc
                            gbest = particles[i].copy()
                    
                    # Update velocities and positions
                    for i in range(n_particles):
                        r1, r2 = np.random.rand(), np.random.rand()
                        
                        for d in range(3):
                            velocities[i][d] = (
                                w * velocities[i][d] +
                                c1 * r1 * (pbest[i][d] - particles[i][d]) +
                                c2 * r2 * (gbest[d] - particles[i][d])
                            )
                            particles[i][d] += velocities[i][d]
                        
                        # Clamp to bounds
                        particles[i][0] = np.clip(particles[i][0], bounds['lstm'][0], bounds['lstm'][1])
                        particles[i][0] = min([32, 64, 128], key=lambda x: abs(x - particles[i][0]))
                        particles[i][1] = np.clip(particles[i][1], bounds['dropout'][0], bounds['dropout'][1])
                        particles[i][2] = np.clip(particles[i][2], bounds['lr'][0], bounds['lr'][1])
                    
                    logger.info(f"    â””â”€ Best so far: {gbest_score:.4f}")
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="PSO",
                    best_accuracy=float(gbest_score),
                    best_lstm_units=int(gbest[0]),
                    best_dropout=float(gbest[1]),
                    best_learning_rate=float(gbest[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_iterations * n_particles,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… PSO Complete: Best={gbest_score:.4f}")
                
                checkpoint_mgr.save_checkpoint("PSO", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ PSO failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.7: TABU SEARCH
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.7: TABU SEARCH")
        logger.info("â”€"*70)
        
        tabu_checkpoint = checkpoint_mgr.load_checkpoint("TabuSearch")
        
        if tabu_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**tabu_checkpoint))
        else:
            try:
                logger.info("Running Tabu Search (10 iterations, tabu_size=5)...")
                start_time = time.time()
                
                # Initial solution
                current = [64, 0.35, 0.005]
                current_score = fitness_function(HyperparameterConfig(*current))
                
                best = current.copy()
                best_score = current_score
                
                tabu_list = []
                tabu_size = 5
                n_iterations = 10
                
                lstm_options = [32, 64, 128]
                
                for iter_num in range(n_iterations):
                    logger.info(f"  Tabu Iteration {iter_num + 1}/{n_iterations}")
                    
                    # Generate neighbors
                    neighbors = []
                    
                    # LSTM neighbors
                    for lstm_val in lstm_options:
                        if lstm_val != current[0]:
                            neighbors.append([lstm_val, current[1], current[2]])
                    
                    # Dropout neighbors
                    for delta in [-0.1, 0.1]:
                        new_drop = np.clip(current[1] + delta, 0.2, 0.5)
                        neighbors.append([current[0], new_drop, current[2]])
                    
                    # LR neighbors
                    for factor in [0.5, 2.0]:
                        new_lr = np.clip(current[2] * factor, 0.001, 0.01)
                        neighbors.append([current[0], current[1], new_lr])
                    
                    # Evaluate non-tabu neighbors
                    best_neighbor = None
                    best_neighbor_score = -1
                    
                    for neighbor in neighbors:
                        neighbor_tuple = tuple(np.round(neighbor, 4))
                        
                        # Skip if tabu (unless aspiration criteria met)
                        if neighbor_tuple in tabu_list:
                            continue
                        
                        config = HyperparameterConfig(
                            int(neighbor[0]),
                            neighbor[1],
                            neighbor[2]
                        )
                        score = fitness_function(config)
                        
                        if score > best_neighbor_score:
                            best_neighbor_score = score
                            best_neighbor = neighbor
                    
                    if best_neighbor is not None:
                        current = best_neighbor
                        current_score = best_neighbor_score
                        
                        # Update tabu list
                        tabu_list.append(tuple(np.round(current, 4)))
                        if len(tabu_list) > tabu_size:
                            tabu_list.pop(0)
                        
                        # Update global best
                        if current_score > best_score:
                            best = current.copy()
                            best_score = current_score
                        
                        logger.info(f"    â””â”€ Current: {current_score:.4f} | Best: {best_score:.4f}")
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="TabuSearch",
                    best_accuracy=float(best_score),
                    best_lstm_units=int(best[0]),
                    best_dropout=float(best[1]),
                    best_learning_rate=float(best[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_iterations,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… Tabu Search Complete: Best={best_score:.4f}")
                
                checkpoint_mgr.save_checkpoint("TabuSearch", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ Tabu Search failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.8: GREY WOLF OPTIMIZER (GWO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.8: GREY WOLF OPTIMIZER")
        logger.info("â”€"*70)
        
        gwo_checkpoint = checkpoint_mgr.load_checkpoint("GWO")
        
        if gwo_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**gwo_checkpoint))
        else:
            try:
                logger.info("Running GWO (5 wolves, 3 iterations)...")
                start_time = time.time()
                
                n_wolves = 5
                n_iterations = 3
                bounds = {'lstm': (32, 128), 'dropout': (0.2, 0.5), 'lr': (0.001, 0.01)}
                
                # Initialize wolves
                wolves = []
                scores = []
                
                for _ in range(n_wolves):
                    lstm = int(np.random.uniform(bounds['lstm'][0], bounds['lstm'][1]))
                    lstm = min([32, 64, 128], key=lambda x: abs(x - lstm))
                    dropout = np.random.uniform(bounds['dropout'][0], bounds['dropout'][1])
                    lr = np.random.uniform(bounds['lr'][0], bounds['lr'][1])
                    
                    wolves.append(np.array([lstm, dropout, lr]))
                    config = HyperparameterConfig(lstm, dropout, lr)
                    scores.append(fitness_function(config))
                
                # Identify alpha, beta, delta
                sorted_indices = np.argsort(scores)[::-1]
                alpha_idx, beta_idx, delta_idx = sorted_indices[:3]
                
                for iter_num in range(n_iterations):
                    logger.info(f"  GWO Iteration {iter_num + 1}/{n_iterations}")
                    
                    a = 2 - iter_num * (2.0 / n_iterations)  # Decreasing from 2 to 0
                    
                    for i in range(n_wolves):
                        # Update position based on alpha, beta, delta
                        r1, r2 = np.random.rand(), np.random.rand()
                        A1 = 2 * a * r1 - a
                        C1 = 2 * r2
                        
                        D_alpha = abs(C1 * wolves[alpha_idx] - wolves[i])
                        X1 = wolves[alpha_idx] - A1 * D_alpha
                        
                        r1, r2 = np.random.rand(), np.random.rand()
                        A2 = 2 * a * r1 - a
                        C2 = 2 * r2
                        
                        D_beta = abs(C2 * wolves[beta_idx] - wolves[i])
                        X2 = wolves[beta_idx] - A2 * D_beta
                        
                        r1, r2 = np.random.rand(), np.random.rand()
                        A3 = 2 * a * r1 - a
                        C3 = 2 * r2
                        
                        D_delta = abs(C3 * wolves[delta_idx] - wolves[i])
                        X3 = wolves[delta_idx] - A3 * D_delta
                        
                        wolves[i] = (X1 + X2 + X3) / 3
                        
                        # Clamp bounds
                        wolves[i][0] = np.clip(wolves[i][0], bounds['lstm'][0], bounds['lstm'][1])
                        wolves[i][0] = min([32, 64, 128], key=lambda x: abs(x - wolves[i][0]))
                        wolves[i][1] = np.clip(wolves[i][1], bounds['dropout'][0], bounds['dropout'][1])
                        wolves[i][2] = np.clip(wolves[i][2], bounds['lr'][0], bounds['lr'][1])
                        
                        # Evaluate
                        config = HyperparameterConfig(int(wolves[i][0]), wolves[i][1], wolves[i][2])
                        scores[i] = fitness_function(config)
                    
                    # Update hierarchy
                    sorted_indices = np.argsort(scores)[::-1]
                    alpha_idx, beta_idx, delta_idx = sorted_indices[:3]
                    
                    logger.info(f"    â””â”€ Alpha score: {scores[alpha_idx]:.4f}")
                
                exec_time = time.time() - start_time
                best_wolf = wolves[alpha_idx]
                
                result = AlgorithmResult(
                    algorithm_name="GWO",
                    best_accuracy=float(scores[alpha_idx]),
                    best_lstm_units=int(best_wolf[0]),
                    best_dropout=float(best_wolf[1]),
                    best_learning_rate=float(best_wolf[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_iterations * n_wolves,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… GWO Complete: Best={scores[alpha_idx]:.4f}")
                
                checkpoint_mgr.save_checkpoint("GWO", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ GWO failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.9: WHALE OPTIMIZATION ALGORITHM (WOA)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.9: WHALE OPTIMIZATION ALGORITHM")
        logger.info("â”€"*70)
        
        woa_checkpoint = checkpoint_mgr.load_checkpoint("WOA")
        
        if woa_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**woa_checkpoint))
        else:
            try:
                logger.info("Running WOA (5 whales, 3 iterations)...")
                start_time = time.time()
                
                n_whales = 5
                n_iterations = 3
                bounds = {'lstm': (32, 128), 'dropout': (0.2, 0.5), 'lr': (0.001, 0.01)}
                
                # Initialize whales
                whales = []
                scores = []
                
                for _ in range(n_whales):
                    lstm = int(np.random.uniform(bounds['lstm'][0], bounds['lstm'][1]))
                    lstm = min([32, 64, 128], key=lambda x: abs(x - lstm))
                    dropout = np.random.uniform(bounds['dropout'][0], bounds['dropout'][1])
                    lr = np.random.uniform(bounds['lr'][0], bounds['lr'][1])
                    
                    whales.append(np.array([lstm, dropout, lr]))
                    config = HyperparameterConfig(lstm, dropout, lr)
                    scores.append(fitness_function(config))
                
                # Find best whale
                best_idx = np.argmax(scores)
                best_whale = whales[best_idx].copy()
                best_score = scores[best_idx]
                
                for iter_num in range(n_iterations):
                    logger.info(f"  WOA Iteration {iter_num + 1}/{n_iterations}")
                    
                    a = 2 - iter_num * (2.0 / n_iterations)
                    b = 1  # Spiral shape parameter
                    
                    for i in range(n_whales):
                        r = np.random.rand()
                        A = 2 * a * r - a
                        C = 2 * r
                        p = np.random.rand()
                        l = np.random.uniform(-1, 1)
                        
                        if p < 0.5:
                            if abs(A) < 1:
                                # Encircling prey
                                D = abs(C * best_whale - whales[i])
                                whales[i] = best_whale - A * D
                            else:
                                # Exploration
                                rand_idx = np.random.randint(0, n_whales)
                                D = abs(C * whales[rand_idx] - whales[i])
                                whales[i] = whales[rand_idx] - A * D
                        else:
                            # Spiral bubble-net
                            D = abs(best_whale - whales[i])
                            whales[i] = D * np.exp(b * l) * np.cos(2 * np.pi * l) + best_whale
                        
                        # Clamp bounds
                        whales[i][0] = np.clip(whales[i][0], bounds['lstm'][0], bounds['lstm'][1])
                        whales[i][0] = min([32, 64, 128], key=lambda x: abs(x - whales[i][0]))
                        whales[i][1] = np.clip(whales[i][1], bounds['dropout'][0], bounds['dropout'][1])
                        whales[i][2] = np.clip(whales[i][2], bounds['lr'][0], bounds['lr'][1])
                        
                        # Evaluate
                        config = HyperparameterConfig(int(whales[i][0]), whales[i][1], whales[i][2])
                        scores[i] = fitness_function(config)
                        
                        if scores[i] > best_score:
                            best_score = scores[i]
                            best_whale = whales[i].copy()
                    
                    logger.info(f"    â””â”€ Best score: {best_score:.4f}")
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="WOA",
                    best_accuracy=float(best_score),
                    best_lstm_units=int(best_whale[0]),
                    best_dropout=float(best_whale[1]),
                    best_learning_rate=float(best_whale[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_iterations * n_whales,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… WOA Complete: Best={best_score:.4f}")
                
                checkpoint_mgr.save_checkpoint("WOA", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ WOA failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.10: DIFFERENTIAL EVOLUTION (DE)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.10: DIFFERENTIAL EVOLUTION")
        logger.info("â”€"*70)
        
        de_checkpoint = checkpoint_mgr.load_checkpoint("DE")
        
        if de_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**de_checkpoint))
        else:
            try:
                logger.info("Running DE (pop=5, gen=3, F=0.8, CR=0.7)...")
                start_time = time.time()
                
                pop_size = 5
                n_generations = 3
                F = 0.8  # Mutation factor
                CR = 0.7  # Crossover rate
                bounds = {'lstm': (32, 128), 'dropout': (0.2, 0.5), 'lr': (0.001, 0.01)}
                
                # Initialize population
                population = []
                scores = []
                
                for _ in range(pop_size):
                    lstm = int(np.random.uniform(bounds['lstm'][0], bounds['lstm'][1]))
                    lstm = min([32, 64, 128], key=lambda x: abs(x - lstm))
                    dropout = np.random.uniform(bounds['dropout'][0], bounds['dropout'][1])
                    lr = np.random.uniform(bounds['lr'][0], bounds['lr'][1])
                    
                    population.append(np.array([lstm, dropout, lr]))
                    config = HyperparameterConfig(lstm, dropout, lr)
                    scores.append(fitness_function(config))
                
                best_idx = np.argmax(scores)
                best_individual = population[best_idx].copy()
                best_score = scores[best_idx]
                
                for gen in range(n_generations):
                    logger.info(f"  DE Generation {gen + 1}/{n_generations}")
                    
                    for i in range(pop_size):
                        # Mutation: select 3 random individuals
                        indices = [idx for idx in range(pop_size) if idx != i]
                        a, b, c = population[np.random.choice(indices, 3, replace=False)]
                        
                        # Mutant vector
                        mutant = a + F * (b - c)
                        
                        # Crossover
                        trial = np.copy(population[i])
                        for d in range(3):
                            if np.random.rand() < CR:
                                trial[d] = mutant[d]
                        
                        # Clamp bounds
                        trial[0] = np.clip(trial[0], bounds['lstm'][0], bounds['lstm'][1])
                        trial[0] = min([32, 64, 128], key=lambda x: abs(x - trial[0]))
                        trial[1] = np.clip(trial[1], bounds['dropout'][0], bounds['dropout'][1])
                        trial[2] = np.clip(trial[2], bounds['lr'][0], bounds['lr'][1])
                        
                        # Selection
                        config = HyperparameterConfig(int(trial[0]), trial[1], trial[2])
                        trial_score = fitness_function(config)
                        
                        if trial_score > scores[i]:
                            population[i] = trial
                            scores[i] = trial_score
                            
                            if trial_score > best_score:
                                best_score = trial_score
                                best_individual = trial.copy()
                    
                    logger.info(f"    â””â”€ Best score: {best_score:.4f}")
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="DE",
                    best_accuracy=float(best_score),
                    best_lstm_units=int(best_individual[0]),
                    best_dropout=float(best_individual[1]),
                    best_learning_rate=float(best_individual[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_generations * pop_size,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… DE Complete: Best={best_score:.4f}")
                
                checkpoint_mgr.save_checkpoint("DE", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ DE failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.11: SIMULATED ANNEALING (SA)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "â”€"*70)
        logger.info("PHASE 1.11: SIMULATED ANNEALING")
        logger.info("â”€"*70)
        
        sa_checkpoint = checkpoint_mgr.load_checkpoint("SA")
        
        if sa_checkpoint:
            logger.info("âœ… Loaded from checkpoint")
            results_list.append(AlgorithmResult(**sa_checkpoint))
        else:
            try:
                logger.info("Running SA (20 iterations, T0=100, Î±=0.9)...")
                start_time = time.time()
                
                n_iterations = 20
                T0 = 100.0
                alpha = 0.9
                
                # Initial solution
                current = np.array([64, 0.35, 0.005])
                current_config = HyperparameterConfig(int(current[0]), current[1], current[2])
                current_score = fitness_function(current_config)
                
                best = current.copy()
                best_score = current_score
                
                bounds = {'lstm': (32, 128), 'dropout': (0.2, 0.5), 'lr': (0.001, 0.01)}
                lstm_options = [32, 64, 128]
                
                for iter_num in range(n_iterations):
                    T = T0 * (alpha ** iter_num)
                    logger.info(f"  SA Iteration {iter_num + 1}/{n_iterations} (T={T:.2f})")
                    
                    # Generate neighbor
                    neighbor = current.copy()
                    
                    # Perturb one dimension
                    dim = np.random.randint(0, 3)
                    
                    if dim == 0:  # LSTM
                        current_idx = lstm_options.index(int(current[0]))
                        if np.random.rand() < 0.5 and current_idx < len(lstm_options) - 1:
                            neighbor[0] = lstm_options[current_idx + 1]
                        elif current_idx > 0:
                            neighbor[0] = lstm_options[current_idx - 1]
                    elif dim == 1:  # Dropout
                        neighbor[1] += np.random.uniform(-0.1, 0.1)
                        neighbor[1] = np.clip(neighbor[1], bounds['dropout'][0], bounds['dropout'][1])
                    else:  # LR
                        neighbor[2] *= np.random.uniform(0.5, 2.0)
                        neighbor[2] = np.clip(neighbor[2], bounds['lr'][0], bounds['lr'][1])
                    
                    # Evaluate neighbor
                    neighbor_config = HyperparameterConfig(int(neighbor[0]), neighbor[1], neighbor[2])
                    neighbor_score = fitness_function(neighbor_config)
                    
                    # Acceptance criterion
                    delta = neighbor_score - current_score
                    
                    if delta > 0 or np.random.rand() < np.exp(delta / T):
                        current = neighbor
                        current_score = neighbor_score
                        
                        if current_score > best_score:
                            best = current.copy()
                            best_score = current_score
                    
                    logger.info(f"    â””â”€ Current: {current_score:.4f} | Best: {best_score:.4f}")
                
                exec_time = time.time() - start_time
                
                result = AlgorithmResult(
                    algorithm_name="SA",
                    best_accuracy=float(best_score),
                    best_lstm_units=int(best[0]),
                    best_dropout=float(best[1]),
                    best_learning_rate=float(best[2]),
                    execution_time_seconds=float(exec_time),
                    iterations_completed=n_iterations,
                    timestamp=datetime.now().isoformat()
                )
                
                logger.info(f"âœ… SA Complete: Best={best_score:.4f}")
                
                checkpoint_mgr.save_checkpoint("SA", result.to_dict())
                results_list.append(result)
                
            except Exception as e:
                logger.error(f"âŒ SA failed: {e}\n{traceback.format_exc()}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PHASE 1.12: RESULTS AGGREGATION & EXPORT
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        logger.info("\n" + "="*70)
        logger.info("PHASE 1.12: RESULTS AGGREGATION")
        logger.info("="*70)
        
        # Create results summary
        results_dict = {
            "baseline_accuracy": float(baseline_acc),
            "algorithms": [r.to_dict() for r in results_list],
            "summary": {
                "total_algorithms": len(results_list),
                "best_algorithm": max(results_list, key=lambda x: x.best_accuracy).algorithm_name if results_list else "None",
                "best_accuracy": max([r.best_accuracy for r in results_list]) if results_list else 0.0,
                "total_runtime_seconds": sum([r.execution_time_seconds for r in results_list]),
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # Save final results
        results_file = checkpoint_dir / "phase1_results.json"
        with open(results_file, 'w') as f:
            json.dump(results_dict, f, indent=2)
        
        logger.info(f"âœ… Results saved to {results_file}")
        
        # Print summary table
        logger.info("\n" + "â”€"*70)
        logger.info("RESULTS SUMMARY")
        logger.info("â”€"*70)
        logger.info(f"{'Algorithm':<15} {'Accuracy':<10} {'LSTM':<8} {'Dropout':<10} {'LR':<12} {'Time(s)':<10}")
        logger.info("â”€"*70)
        logger.info(f"{'Baseline':<15} {baseline_acc:<10.4f} {64:<8} {0.3:<10.3f} {0.001:<12.6f} {'N/A':<10}")
        
        for result in results_list:
            logger.info(
                f"{result.algorithm_name:<15} "
                f"{result.best_accuracy:<10.4f} "
                f"{result.best_lstm_units:<8} "
                f"{result.best_dropout:<10.3f} "
                f"{result.best_learning_rate:<12.6f} "
                f"{result.execution_time_seconds:<10.2f}"
            )
        
        logger.info("â”€"*70)
        logger.info(f"ğŸ† Best Algorithm: {results_dict['summary']['best_algorithm']}")
        logger.info(f"ğŸ¯ Best Accuracy: {results_dict['summary']['best_accuracy']:.4f}")
        logger.info(f"â±ï¸  Total Runtime: {results_dict['summary']['total_runtime_seconds']:.2f}s")
        logger.info("="*70)
        
        # Commit volume
        volume.commit()
        logger.info("\nâœ… PHASE 1 COMPLETE - All checkpoints saved to Modal Volume")
        
        return results_dict
        
    except Exception as e:
        logger.critical(f"\nâŒ CRITICAL ERROR: {e}")
        logger.critical(traceback.format_exc())
        logger.info("âš ï¸ Saving partial results before exit...")
        volume.commit()
        raise


@app.local_entrypoint()
def main():
    """Entry point for Modal execution"""
    print("ğŸš€ Starting Phase 1 with Complete Pipeline")
    print("ğŸ“Š 7 Metaheuristic Algorithms + DOE Implementation")
    print("â”€" * 70)
    results = run_phase1_training.remote()
    print("\nâœ… Training completed!")
    print(f"ğŸ† Best Algorithm: {results['summary']['best_algorithm']}")
    print(f"ğŸ¯ Best Accuracy: {results['summary']['best_accuracy']:.4f}")
    print(f"â±ï¸  Total Runtime: {results['summary']['total_runtime_seconds']:.2f}s")