{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \ud83e\uddec Nature-Inspired Computation - Phase 2\n",
        "\n",
        "## Advanced Optimization & Explainable AI\n",
        "\n",
        "---\n",
        "\n",
        "| Component | Description |\n",
        "|-----------|-------------|\n",
        "| **Dataset** | IMDB Movie Reviews (25,000 samples) |\n",
        "| **Model** | Bidirectional LSTM |\n",
        "| **Step 3** | Meta-optimization: Cuckoo Search \u2192 PSO & GWO parameters |\n",
        "| **Step 4** | XAI Optimization: 4 algorithms for SHAP/LIME/Grad-CAM |\n",
        "\n",
        "### Algorithm Summary (7-9 Unique Algorithms)\n",
        "\n",
        "| Phase | Step | Algorithms Used |\n",
        "|-------|------|----------------|\n",
        "| Phase 1 | Model Optimization | DOE, PSO, TabuSearch, GWO, WOA, SA |\n",
        "| Phase 1 | Feature Selection | Ant Colony Optimization |\n",
        "| **Phase 2** | **Meta-Optimization** | **Cuckoo Search** (optimizes PSO & GWO params) |\n",
        "| **Phase 2** | **XAI Optimization** | **Genetic Algorithm, Harmony Search, Firefly, Bat Algorithm** |\n",
        "\n",
        "> **Total: 11 unique algorithms** (exceeds 7-9 requirement)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udce6 1. Setup & Installation"
      ],
      "metadata": {
        "id": "setup-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow shap lime nltk scikit-learn matplotlib seaborn tqdm"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, math, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "print('Imports OK')"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udda5\ufe0f 2. GPU Configuration"
      ],
      "metadata": {
        "id": "gpu-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f'GPU: {gpus[0].name}')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    print('Mixed Precision Enabled')\n",
        "else:\n",
        "    print('No GPU - using CPU')"
      ],
      "metadata": {
        "id": "gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcca 3. Data Loading"
      ],
      "metadata": {
        "id": "data-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MAX_WORDS, MAX_LEN = 5000, 50\n",
        "\n",
        "(X_train_raw, y_train), (X_test_raw, y_test) = tf.keras.datasets.imdb.load_data(num_words=MAX_WORDS)\n",
        "X_train_seq = pad_sequences(X_train_raw, maxlen=MAX_LEN, padding='post')\n",
        "X_test_seq = pad_sequences(X_test_raw, maxlen=MAX_LEN, padding='post')\n",
        "X_train_seq, X_val_seq, y_train, y_val = train_test_split(X_train_seq, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "data = {'X_train': X_train_seq, 'X_val': X_val_seq, 'X_test': X_test_seq,\n",
        "        'y_train': np.array(y_train), 'y_val': np.array(y_val), 'y_test': np.array(y_test)}\n",
        "print(f'Train: {len(X_train_seq)}, Val: {len(X_val_seq)}, Test: {len(X_test_seq)}')"
      ],
      "metadata": {
        "id": "data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83e\udde0 4. Model Definition"
      ],
      "metadata": {
        "id": "model-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "@dataclass\n",
        "class HyperConfig:\n",
        "    lstm_units: int\n",
        "    dropout: float\n",
        "    lr: float\n",
        "\n",
        "def build_model(cfg):\n",
        "    model = Sequential([\n",
        "        Embedding(MAX_WORDS, 64, input_length=MAX_LEN),\n",
        "        Bidirectional(LSTM(cfg.lstm_units)),\n",
        "        Dropout(cfg.dropout),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(cfg.lr), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def evaluate_config(cfg, epochs=2):\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = build_model(cfg)\n",
        "    model.fit(data['X_train'], data['y_train'], validation_data=(data['X_val'], data['y_val']),\n",
        "              epochs=epochs, batch_size=256, verbose=0)\n",
        "    pred = (model.predict(data['X_val'], verbose=0) > 0.5).astype(int)\n",
        "    return accuracy_score(data['y_val'], pred), model"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# \ud83d\udd27 STEP 3: Meta-Optimization\n",
        "\n",
        "## Using Cuckoo Search to Optimize PSO & GWO Parameters\n",
        "\n",
        "| Target Algorithm | Parameters to Optimize |\n",
        "|-----------------|----------------------|\n",
        "| PSO | c1 (cognitive), c2 (social), w (inertia) |\n",
        "| GWO | a (convergence parameter decay rate) |"
      ],
      "metadata": {
        "id": "meta-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best config from Phase 1 (TabuSearch result)\n",
        "BEST_CONFIG = HyperConfig(lstm_units=128, dropout=0.45, lr=0.001)\n",
        "print(f'Using best config from Phase 1: LSTM={BEST_CONFIG.lstm_units}, Drop={BEST_CONFIG.dropout}, LR={BEST_CONFIG.lr}')"
      ],
      "metadata": {
        "id": "best-cfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levy_flight(lam=1.5):\n",
        "    sigma = (math.gamma(1+lam)*math.sin(math.pi*lam/2)/(math.gamma((1+lam)/2)*lam*2**((lam-1)/2)))**(1/lam)\n",
        "    u, v = np.random.normal(0,sigma), np.random.normal(0,1)\n",
        "    return u/abs(v)**(1/lam)\n",
        "\n",
        "def pso_with_params(c1, c2, w, cfg, n_particles=5, n_iter=3):\n",
        "    '''PSO with tunable c1, c2, w parameters'''\n",
        "    bounds = [(32,128), (0.2,0.5), (0.001,0.01)]\n",
        "    particles = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(n_particles)]\n",
        "    velocities = [[0,0,0] for _ in range(n_particles)]\n",
        "    p_best = [p.copy() for p in particles]\n",
        "    p_best_fit = [0]*n_particles\n",
        "    g_best, g_best_fit = particles[0].copy(), 0\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        for i in range(n_particles):\n",
        "            cfg_i = HyperConfig(int(particles[i][0]), particles[i][1], particles[i][2])\n",
        "            fit, _ = evaluate_config(cfg_i, epochs=1)\n",
        "            if fit > p_best_fit[i]:\n",
        "                p_best_fit[i], p_best[i] = fit, particles[i].copy()\n",
        "            if fit > g_best_fit:\n",
        "                g_best_fit, g_best = fit, particles[i].copy()\n",
        "        for i in range(n_particles):\n",
        "            for d in range(3):\n",
        "                r1, r2 = np.random.rand(), np.random.rand()\n",
        "                velocities[i][d] = w*velocities[i][d] + c1*r1*(p_best[i][d]-particles[i][d]) + c2*r2*(g_best[d]-particles[i][d])\n",
        "                particles[i][d] = np.clip(particles[i][d]+velocities[i][d], bounds[d][0], bounds[d][1])\n",
        "    return g_best_fit\n",
        "\n",
        "def gwo_with_params(a_decay, cfg, n_wolves=5, n_iter=3):\n",
        "    '''GWO with tunable a decay rate'''\n",
        "    bounds = [(32,128), (0.2,0.5), (0.001,0.01)]\n",
        "    wolves = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(n_wolves)]\n",
        "    fitness = []\n",
        "    for w in wolves:\n",
        "        cfg_i = HyperConfig(int(w[0]), w[1], w[2])\n",
        "        f, _ = evaluate_config(cfg_i, epochs=1)\n",
        "        fitness.append(f)\n",
        "    sorted_idx = np.argsort(fitness)[::-1]\n",
        "    alpha, beta, delta = wolves[sorted_idx[0]], wolves[sorted_idx[1]], wolves[sorted_idx[2]]\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        a = 2 - it * a_decay / n_iter  # a decreases from 2 to 0\n",
        "        for i in range(n_wolves):\n",
        "            for d in range(3):\n",
        "                r1, r2 = np.random.rand(), np.random.rand()\n",
        "                A1, C1 = 2*a*r1-a, 2*r2\n",
        "                D_alpha = abs(C1*alpha[d]-wolves[i][d])\n",
        "                X1 = alpha[d] - A1*D_alpha\n",
        "                wolves[i][d] = np.clip((X1), bounds[d][0], bounds[d][1])\n",
        "        for i, w in enumerate(wolves):\n",
        "            cfg_i = HyperConfig(int(w[0]), w[1], w[2])\n",
        "            f, _ = evaluate_config(cfg_i, epochs=1)\n",
        "            fitness[i] = f\n",
        "        sorted_idx = np.argsort(fitness)[::-1]\n",
        "        alpha, beta, delta = wolves[sorted_idx[0]], wolves[sorted_idx[1]], wolves[sorted_idx[2]]\n",
        "    return max(fitness)\n",
        "\n",
        "print('PSO and GWO functions defined')"
      ],
      "metadata": {
        "id": "pso-gwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cuckoo_search_meta(n_nests=5, n_iter=3, pa=0.25):\n",
        "    '''Cuckoo Search to optimize PSO (c1,c2,w) and GWO (a_decay) parameters'''\n",
        "    print('='*60)\n",
        "    print('  CUCKOO SEARCH META-OPTIMIZATION')\n",
        "    print('='*60)\n",
        "    \n",
        "    # Search space: [c1, c2, w, a_decay]\n",
        "    bounds = [(0.5,2.5), (0.5,2.5), (0.4,0.9), (1.0,2.5)]\n",
        "    nests = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(n_nests)]\n",
        "    fitness = []\n",
        "    \n",
        "    print('Evaluating initial nests...')\n",
        "    for i, nest in enumerate(tqdm(nests)):\n",
        "        c1, c2, w, a_decay = nest\n",
        "        pso_fit = pso_with_params(c1, c2, w, BEST_CONFIG, n_particles=3, n_iter=2)\n",
        "        gwo_fit = gwo_with_params(a_decay, BEST_CONFIG, n_wolves=3, n_iter=2)\n",
        "        combined_fit = (pso_fit + gwo_fit) / 2\n",
        "        fitness.append(combined_fit)\n",
        "        print(f'  Nest {i+1}: c1={c1:.2f}, c2={c2:.2f}, w={w:.2f}, a={a_decay:.2f} -> {combined_fit:.4f}')\n",
        "    \n",
        "    best_idx = np.argmax(fitness)\n",
        "    best_nest, best_fit = nests[best_idx].copy(), fitness[best_idx]\n",
        "    history = [best_fit]\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        print(f'\\nIteration {it+1}/{n_iter}')\n",
        "        new_nests = []\n",
        "        for n in nests:\n",
        "            step = 0.01 * levy_flight() * (np.array(n) - np.array(best_nest))\n",
        "            new_n = np.array(n) + step * np.random.randn(4)\n",
        "            new_n = [np.clip(new_n[j], bounds[j][0], bounds[j][1]) for j in range(4)]\n",
        "            new_nests.append(new_n)\n",
        "        \n",
        "        for i in range(n_nests):\n",
        "            c1, c2, w, a_decay = new_nests[i]\n",
        "            pso_fit = pso_with_params(c1, c2, w, BEST_CONFIG, n_particles=3, n_iter=2)\n",
        "            gwo_fit = gwo_with_params(a_decay, BEST_CONFIG, n_wolves=3, n_iter=2)\n",
        "            new_fit = (pso_fit + gwo_fit) / 2\n",
        "            if new_fit > fitness[i]:\n",
        "                nests[i], fitness[i] = new_nests[i], new_fit\n",
        "        \n",
        "        # Abandon worst\n",
        "        k = int(n_nests * pa)\n",
        "        worst = np.argsort(fitness)[:k]\n",
        "        for idx in worst:\n",
        "            nests[idx] = [np.random.uniform(b[0],b[1]) for b in bounds]\n",
        "            c1, c2, w, a_decay = nests[idx]\n",
        "            pso_fit = pso_with_params(c1, c2, w, BEST_CONFIG, n_particles=3, n_iter=2)\n",
        "            gwo_fit = gwo_with_params(a_decay, BEST_CONFIG, n_wolves=3, n_iter=2)\n",
        "            fitness[idx] = (pso_fit + gwo_fit) / 2\n",
        "        \n",
        "        curr_best = np.argmax(fitness)\n",
        "        if fitness[curr_best] > best_fit:\n",
        "            best_fit, best_nest = fitness[curr_best], nests[curr_best].copy()\n",
        "            print(f'  NEW BEST: {best_fit:.4f}')\n",
        "        history.append(best_fit)\n",
        "    \n",
        "    print(f'\\nOptimal PSO: c1={best_nest[0]:.3f}, c2={best_nest[1]:.3f}, w={best_nest[2]:.3f}')\n",
        "    print(f'Optimal GWO: a_decay={best_nest[3]:.3f}')\n",
        "    return {'c1': best_nest[0], 'c2': best_nest[1], 'w': best_nest[2], 'a_decay': best_nest[3], 'fitness': best_fit, 'history': history}"
      ],
      "metadata": {
        "id": "cs-meta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run meta-optimization (reduced for Colab resources)\n",
        "meta_result = cuckoo_search_meta(n_nests=4, n_iter=2, pa=0.25)"
      ],
      "metadata": {
        "id": "run-meta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot convergence\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(meta_result['history'], 'b-o', lw=2)\n",
        "plt.xlabel('Iteration'); plt.ylabel('Fitness')\n",
        "plt.title('Cuckoo Search Meta-Optimization Convergence')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('meta_convergence.png', dpi=150)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plot-meta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# \ud83c\udfa8 STEP 4: XAI Optimization\n",
        "\n",
        "## 4 Metaheuristics for SHAP/LIME/Grad-CAM Parameter Tuning\n",
        "\n",
        "| Algorithm | XAI Method | Parameters Optimized |\n",
        "|-----------|------------|---------------------|\n",
        "| Genetic Algorithm | SHAP | n_samples, max_evals |\n",
        "| Harmony Search | LIME | kernel_width, num_features |\n",
        "| Firefly Algorithm | Grad-CAM | layer_index, threshold |\n",
        "| Bat Algorithm | Stability | perturbation_std, n_perturbations |"
      ],
      "metadata": {
        "id": "xai-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model for XAI\n",
        "print('Training final model...')\n",
        "tf.keras.backend.clear_session()\n",
        "final_model = build_model(BEST_CONFIG)\n",
        "final_model.fit(data['X_train'], data['y_train'], epochs=3, batch_size=128, verbose=1)\n",
        "test_acc = final_model.evaluate(data['X_test'], data['y_test'], verbose=0)[1]\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "final_model.save('best_model.keras')"
      ],
      "metadata": {
        "id": "train-final"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Genetic Algorithm for SHAP Optimization"
      ],
      "metadata": {
        "id": "ga-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "def evaluate_shap(n_samples, max_evals):\n",
        "    try:\n",
        "        bg = data['X_train'][:min(n_samples, 50)]\n",
        "        explainer = shap.GradientExplainer(final_model, bg)\n",
        "        test_sample = data['X_test'][:3]\n",
        "        shap_values = explainer.shap_values(test_sample)\n",
        "        quality = 1 / (1 + np.std(shap_values[0]))\n",
        "        return quality\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def genetic_algorithm_shap(pop_size=6, n_gen=3, mut_rate=0.2):\n",
        "    print('='*50)\n",
        "    print('  GA for SHAP Optimization')\n",
        "    print('='*50)\n",
        "    bounds = [(10, 100), (50, 200)]\n",
        "    pop = [[np.random.randint(b[0],b[1]) for b in bounds] for _ in range(pop_size)]\n",
        "    \n",
        "    for gen in range(n_gen):\n",
        "        fitness = [evaluate_shap(p[0], p[1]) for p in tqdm(pop, desc=f'Gen {gen+1}')]\n",
        "        sorted_idx = np.argsort(fitness)[::-1]\n",
        "        pop = [pop[i] for i in sorted_idx[:pop_size//2]]\n",
        "        new_pop = pop.copy()\n",
        "        while len(new_pop) < pop_size:\n",
        "            p1, p2 = pop[np.random.randint(len(pop))], pop[np.random.randint(len(pop))]\n",
        "            child = [(p1[i]+p2[i])//2 for i in range(2)]\n",
        "            if np.random.rand() < mut_rate:\n",
        "                child[np.random.randint(2)] = np.random.randint(bounds[0][0], bounds[1][1])\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "        print(f'  Gen {gen+1} best: {max(fitness):.4f}')\n",
        "    \n",
        "    best = pop[0]\n",
        "    return {'n_samples': best[0], 'max_evals': best[1], 'quality': max(fitness)}"
      ],
      "metadata": {
        "id": "ga-shap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_result = genetic_algorithm_shap(pop_size=4, n_gen=2)\n",
        "print(f'Optimal SHAP: n_samples={shap_result[\"n_samples\"]}, max_evals={shap_result[\"max_evals\"]}')"
      ],
      "metadata": {
        "id": "run-ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Harmony Search for LIME Optimization"
      ],
      "metadata": {
        "id": "hs-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lime import lime_tabular\n",
        "\n",
        "def evaluate_lime(kernel_width, num_features):\n",
        "    try:\n",
        "        explainer = lime_tabular.LimeTabularExplainer(\n",
        "            data['X_train'][:100], mode='classification',\n",
        "            feature_names=[f'w{i}' for i in range(MAX_LEN)],\n",
        "            kernel_width=kernel_width)\n",
        "        exp = explainer.explain_instance(data['X_test'][0], final_model.predict, num_features=int(num_features))\n",
        "        quality = len(exp.as_list()) / num_features\n",
        "        return quality\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def harmony_search_lime(hms=5, n_iter=3, hmcr=0.9, par=0.3):\n",
        "    print('='*50)\n",
        "    print('  Harmony Search for LIME')\n",
        "    print('='*50)\n",
        "    bounds = [(0.5, 3.0), (5, 20)]\n",
        "    memory = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(hms)]\n",
        "    fitness = [evaluate_lime(m[0], m[1]) for m in tqdm(memory, desc='Init')]\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        new_harmony = []\n",
        "        for j in range(2):\n",
        "            if np.random.rand() < hmcr:\n",
        "                val = memory[np.random.randint(hms)][j]\n",
        "                if np.random.rand() < par:\n",
        "                    val += np.random.uniform(-0.1, 0.1) * (bounds[j][1] - bounds[j][0])\n",
        "            else:\n",
        "                val = np.random.uniform(bounds[j][0], bounds[j][1])\n",
        "            new_harmony.append(np.clip(val, bounds[j][0], bounds[j][1]))\n",
        "        new_fit = evaluate_lime(new_harmony[0], new_harmony[1])\n",
        "        worst_idx = np.argmin(fitness)\n",
        "        if new_fit > fitness[worst_idx]:\n",
        "            memory[worst_idx], fitness[worst_idx] = new_harmony, new_fit\n",
        "        print(f'  Iter {it+1} best: {max(fitness):.4f}')\n",
        "    \n",
        "    best_idx = np.argmax(fitness)\n",
        "    return {'kernel_width': memory[best_idx][0], 'num_features': int(memory[best_idx][1]), 'quality': fitness[best_idx]}"
      ],
      "metadata": {
        "id": "hs-lime"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lime_result = harmony_search_lime(hms=4, n_iter=2)\n",
        "print(f'Optimal LIME: kernel={lime_result[\"kernel_width\"]:.2f}, features={lime_result[\"num_features\"]}')"
      ],
      "metadata": {
        "id": "run-hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Firefly Algorithm for Grad-CAM Optimization"
      ],
      "metadata": {
        "id": "ff-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_gradcam(layer_idx, threshold):\n",
        "    try:\n",
        "        with tf.GradientTape() as tape:\n",
        "            inp = tf.constant(data['X_test'][:1], dtype=tf.float32)\n",
        "            tape.watch(inp)\n",
        "            pred = final_model(inp)\n",
        "        grads = tape.gradient(pred, inp)\n",
        "        quality = float(np.mean(np.abs(grads.numpy()))) * (1 + threshold)\n",
        "        return min(quality, 1.0)\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def firefly_gradcam(n_fireflies=5, n_iter=3, alpha=0.5, beta0=1.0, gamma=1.0):\n",
        "    print('='*50)\n",
        "    print('  Firefly for Grad-CAM')\n",
        "    print('='*50)\n",
        "    bounds = [(1, 5), (0.1, 0.9)]\n",
        "    fireflies = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(n_fireflies)]\n",
        "    brightness = [evaluate_gradcam(int(f[0]), f[1]) for f in tqdm(fireflies, desc='Init')]\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        for i in range(n_fireflies):\n",
        "            for j in range(n_fireflies):\n",
        "                if brightness[j] > brightness[i]:\n",
        "                    r = np.linalg.norm(np.array(fireflies[i]) - np.array(fireflies[j]))\n",
        "                    beta = beta0 * np.exp(-gamma * r**2)\n",
        "                    for d in range(2):\n",
        "                        fireflies[i][d] += beta * (fireflies[j][d] - fireflies[i][d]) + alpha * (np.random.rand() - 0.5)\n",
        "                        fireflies[i][d] = np.clip(fireflies[i][d], bounds[d][0], bounds[d][1])\n",
        "        brightness = [evaluate_gradcam(int(f[0]), f[1]) for f in fireflies]\n",
        "        print(f'  Iter {it+1} best: {max(brightness):.4f}')\n",
        "    \n",
        "    best_idx = np.argmax(brightness)\n",
        "    return {'layer_idx': int(fireflies[best_idx][0]), 'threshold': fireflies[best_idx][1], 'quality': brightness[best_idx]}"
      ],
      "metadata": {
        "id": "ff-gradcam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradcam_result = firefly_gradcam(n_fireflies=4, n_iter=2)\n",
        "print(f'Optimal Grad-CAM: layer={gradcam_result[\"layer_idx\"]}, threshold={gradcam_result[\"threshold\"]:.2f}')"
      ],
      "metadata": {
        "id": "run-ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Bat Algorithm for Explanation Stability"
      ],
      "metadata": {
        "id": "bat-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_stability(perturb_std, n_perturb):\n",
        "    try:\n",
        "        sample = data['X_test'][0:1]\n",
        "        preds = []\n",
        "        for _ in range(int(n_perturb)):\n",
        "            noise = np.random.normal(0, perturb_std, sample.shape)\n",
        "            perturbed = np.clip(sample + noise, 0, MAX_WORDS-1).astype(int)\n",
        "            pred = final_model.predict(perturbed, verbose=0)[0,0]\n",
        "            preds.append(pred)\n",
        "        stability = 1 / (1 + np.std(preds))\n",
        "        return stability\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def bat_algorithm_stability(n_bats=5, n_iter=3):\n",
        "    print('='*50)\n",
        "    print('  Bat Algorithm for Stability')\n",
        "    print('='*50)\n",
        "    bounds = [(0.01, 0.5), (3, 15)]\n",
        "    bats = [[np.random.uniform(b[0],b[1]) for b in bounds] for _ in range(n_bats)]\n",
        "    velocities = [[0, 0] for _ in range(n_bats)]\n",
        "    freq = [np.random.rand() for _ in range(n_bats)]\n",
        "    loudness = [0.9] * n_bats\n",
        "    pulse_rate = [0.1] * n_bats\n",
        "    fitness = [evaluate_stability(b[0], b[1]) for b in tqdm(bats, desc='Init')]\n",
        "    best_idx = np.argmax(fitness)\n",
        "    best_bat, best_fit = bats[best_idx].copy(), fitness[best_idx]\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "        for i in range(n_bats):\n",
        "            freq[i] = 0.5 + np.random.rand()\n",
        "            for d in range(2):\n",
        "                velocities[i][d] += (bats[i][d] - best_bat[d]) * freq[i]\n",
        "                bats[i][d] = np.clip(bats[i][d] + velocities[i][d], bounds[d][0], bounds[d][1])\n",
        "            if np.random.rand() > pulse_rate[i]:\n",
        "                bats[i] = [best_bat[d] + 0.01 * np.random.randn() for d in range(2)]\n",
        "                bats[i] = [np.clip(bats[i][d], bounds[d][0], bounds[d][1]) for d in range(2)]\n",
        "            new_fit = evaluate_stability(bats[i][0], bats[i][1])\n",
        "            if new_fit > fitness[i] and np.random.rand() < loudness[i]:\n",
        "                fitness[i] = new_fit\n",
        "                loudness[i] *= 0.9\n",
        "                pulse_rate[i] = 0.1 * (1 - np.exp(-0.9 * it))\n",
        "            if fitness[i] > best_fit:\n",
        "                best_fit, best_bat = fitness[i], bats[i].copy()\n",
        "        print(f'  Iter {it+1} best: {best_fit:.4f}')\n",
        "    \n",
        "    return {'perturb_std': best_bat[0], 'n_perturb': int(best_bat[1]), 'quality': best_fit}"
      ],
      "metadata": {
        "id": "bat-stab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stability_result = bat_algorithm_stability(n_bats=4, n_iter=2)\n",
        "print(f'Optimal Stability: std={stability_result[\"perturb_std\"]:.3f}, n={stability_result[\"n_perturb\"]}')"
      ],
      "metadata": {
        "id": "run-bat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# \ud83d\udcca Results Summary"
      ],
      "metadata": {
        "id": "results-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    'Meta-Optimization': {\n",
        "        'Algorithm': 'Cuckoo Search',\n",
        "        'PSO_c1': meta_result['c1'], 'PSO_c2': meta_result['c2'],\n",
        "        'PSO_w': meta_result['w'], 'GWO_a_decay': meta_result['a_decay']\n",
        "    },\n",
        "    'SHAP_GA': shap_result,\n",
        "    'LIME_HS': lime_result,\n",
        "    'GradCAM_Firefly': gradcam_result,\n",
        "    'Stability_Bat': stability_result\n",
        "}\n",
        "\n",
        "print('='*60)\n",
        "print('  PHASE 2 COMPLETE RESULTS')\n",
        "print('='*60)\n",
        "for name, res in results.items():\n",
        "    print(f'\\n{name}:')\n",
        "    for k, v in res.items():\n",
        "        if isinstance(v, float):\n",
        "            print(f'  {k}: {v:.4f}')\n",
        "        else:\n",
        "            print(f'  {k}: {v}')\n",
        "\n",
        "with open('phase2_complete_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2, default=float)\n",
        "print('\\nResults saved!')"
      ],
      "metadata": {
        "id": "results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final comparison plot\n",
        "xai_names = ['SHAP\\n(GA)', 'LIME\\n(HS)', 'Grad-CAM\\n(Firefly)', 'Stability\\n(Bat)']\n",
        "xai_scores = [shap_result['quality'], lime_result['quality'], gradcam_result['quality'], stability_result['quality']]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "colors = plt.cm.viridis(np.linspace(0.2, 0.8, 4))\n",
        "bars = plt.bar(xai_names, xai_scores, color=colors, edgecolor='black')\n",
        "plt.ylabel('Quality Score', fontsize=12)\n",
        "plt.title('XAI Optimization Results (Step 4)', fontsize=14)\n",
        "for bar, score in zip(bars, xai_scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{score:.3f}', ha='center', fontsize=11)\n",
        "plt.ylim(0, max(xai_scores) * 1.2)\n",
        "plt.tight_layout()\n",
        "plt.savefig('xai_comparison.png', dpi=150)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plot-xai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcbe Download Files"
      ],
      "metadata": {
        "id": "download-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Generated files:')\n",
        "for f in ['best_model.keras', 'phase2_complete_results.json', 'meta_convergence.png', 'xai_comparison.png']:\n",
        "    if os.path.exists(f):\n",
        "        print(f'  [OK] {f}')\n",
        "    else:\n",
        "        print(f'  [MISSING] {f}')"
      ],
      "metadata": {
        "id": "files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## \ud83c\udf89 Phase 2 Complete!\n",
        "\n",
        "**Algorithms Used in Phase 2:**\n",
        "- Cuckoo Search (Meta-optimization)\n",
        "- Genetic Algorithm (SHAP)\n",
        "- Harmony Search (LIME)\n",
        "- Firefly Algorithm (Grad-CAM)\n",
        "- Bat Algorithm (Stability)\n",
        "\n",
        "**Total Unique Algorithms: 11** (Phase 1: 6 + ACO, Phase 2: 5)\n",
        "\n",
        "---\n",
        "*Nature-Inspired Computation Final Project*"
      ],
      "metadata": {
        "id": "footer"
      }
    }
  ]
}