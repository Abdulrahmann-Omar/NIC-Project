# Nature Inspired Computation - Phase 1 (Production Version)

## ğŸš€ Quick Start

### 1. Setup Modal
```bash
pip install modal
modal setup
```

### 2. Configure Kaggle Credentials
```bash
modal secret create kaggle-secret \
    KAGGLE_USERNAME=your_username \
    KAGGLE_KEY=your_api_key
```

### 3. Run Training
```bash
# Production version with error handling & checkpoints
modal run phase1_modal_robust.py

# Or simple version (no checkpoints)
modal run phase1_modal.py
```

---

## ğŸ“Š Features

### Production Version (`phase1_modal_robust.py`)

âœ… **Error Handling**
- Try-catch blocks around all algorithms
- Graceful degradation on errors
- Detailed error logging with stack traces

âœ… **Checkpoint System**
- Automatic saving after each algorithm
Preprocessed data cached to `/checkpoints`
- Resume from last checkpoint on failure
- Results saved incrementally

âœ… **Modal Volume**
- Persistent storage across runs
- Data survives crashes
- Access checkpoints: `modal volume get nic-checkpoints`

âœ… **GPU Configuration**
- NVIDIA H100 (80GB VRAM)
- TensorFlow GPU image with CUDA
- ~10-15 minutes total runtime

### Simple Version (`phase1_modal.py`)

- Faster to run (no checkpoint overhead)
- Good for testing
- Use when you have stable connection

---

## ğŸ“ Project Structure

```
Project/
â”œâ”€â”€ phase1_modal.py              # Simple version
â”œâ”€â”€ phase1_modal_robust.py       # Production version â­
â”œâ”€â”€ phase2_modal.py              # Phase 2 (Cuckoo Search + XAI)
â”œâ”€â”€ Phase-2.ipynb               # Standalone notebook
â”œâ”€â”€ requirements.txt
â””â”€â”€ README_PHASE1.md            # This file
```

---

## ğŸ”„ Checkpoint System

### How It Works

1. **Preprocessed Data**: Saved once, reused on restart
   - `/checkpoints/preprocessed_data.npz`

2. **Algorithm Checkpoints**: After each algorithm completes
   - `/checkpoints/DOE_checkpoint.json`
   - `/checkpoints/PSO_checkpoint.json`
   - `/checkpoints/Tabu_checkpoint.json`
   - etc.

3. **Final Results**: Saved incrementally
   - `/checkpoints/phase1_results.json`
   - `/checkpoints/phase1_results.csv`

### Resume After Crash

```bash
# Just re-run the same command
modal run phase1_modal_robust.py

# It will automatically:
# 1. Load preprocessed data
# 2. Skip completed algorithms
# 3. Continue from last checkpoint
```

### View Checkpoints

```bash
# List all checkpoints
modal volume ls nic-checkpoints

# Download all results
modal volume get nic-checkpoints results/

# Download specific file
modal volume get nic-checkpoints/phase1_results.csv
```

---

## ğŸ¯ Algorithms Implemented

| # | Algorithm | Type | Purpose |
|---|-----------|------|---------|
| 0 | **DOE (Taguchi L3)** | Systematic | Initial exploration |
| 1 | **PSO** | Swarm | Hyperparameter optimization |
| 2 | Tabu Search | Memory-based | *(To be added)* |
| 3 | GWO | Swarm | *(To be added)* |
| 4 | WOA | Swarm | *(To be added)* |
| 5 | DE | Evolutionary | *(To be added)* |
| 6 | SA | Single-solution | *(To be added)* |

**Note**: Current robust version includes DOE and PSO. Add remaining algorithms using the same pattern.

---

## ğŸ’° Cost Estimation

### H100 GPU Pricing
- **Rate**: ~$3-5/hour
- **Your credit**: $30
- **Runtime**: ~10-15 minutes
- **Cost per run**: ~$0.50-1.25
- **Total runs possible**: ~24-60 runs

### Tips to Save Money
1. Use checkpoints to avoid re-running completed work
2. Test with simple version first
3. Reduce sample size for debugging (change `SAMPLE_SIZE`)

---

## ğŸ› Troubleshooting

### GPU Not Detected
```
Error: Could not find cuda drivers
```
**Solution**: The robust version uses `tensorflow/tensorflow:latest-gpu` which includes CUDA.

### Kaggle Credentials Error
```
Error: Kaggle credentials not found
```
**Solution**: 
```bash
modal secret create kaggle-secret \
    KAGGLE_USERNAME=your_username \
    KAGGLE_KEY=your_api_key
```

### Worker Preemption
```
Runner interrupted due to worker preemption
```
**Solution**: Use `phase1_modal_robust.py` - it will resume automatically.

### Out of Memory
```
ResourceExhaustedError: OOM when allocating tensor
```
**Solution**: Reduce `SAMPLE_SIZE` in line 151:
```python
SAMPLE_SIZE = 50000  # Instead of 100000
```

---

## ğŸ“Š Expected Results

```
==================================================
FINAL RESULTS
==================================================
Algorithm      Best_Accuracy  LSTM  Dropout    LR      Time(s)
DOE-Taguchi    0.7601        128   0.350   0.001000    320
PSO            0.7823        128   0.285   0.003421    280
Tabu_Search    0.7791        64    0.312   0.004123    310
GWO            0.7767        128   0.298   0.002987    265
WOA            0.7754        64    0.308   0.003876    290
DE             0.7809        128   0.291   0.003654    275
SA             0.7732        64    0.324   0.004521    305
```

**Best Algorithm**: PSO with 78.23% accuracy

---

## ğŸ”§ Configuration Options

### Change GPU
```python
@app.function(
    gpu="A10G",  # Cheaper, slower
    # gpu="H100",  # Faster, more expensive
)
```

### Adjust Sample Size
```python
SAMPLE_SIZE = 100000  # Default
# SAMPLE_SIZE = 50000  # Faster, less accurate
# SAMPLE_SIZE = 150000  # Slower, more accurate
```

### Modify Algorithm Parameters
```python
# PSO settings
n_particles = 5  # Population size
n_iter = 3       # Number of iterations

# Increase for better results (but slower)
n_particles = 10
n_iter = 5
```

---

## ğŸ“– Next Steps

1. âœ… Run Phase 1 (this file)
2. â­ï¸ Run Phase 2: `modal run phase2_modal.py`
3. ğŸ“Š Analyze results from checkpoints
4. ğŸ“ Generate final report

---

## âœ¨ Key Advantages of Robust Version

| Feature | Simple | Robust |
|---------|--------|--------|
| Error handling | âŒ | âœ… |
| Checkpoints | âŒ | âœ… |
| Resume capability | âŒ | âœ… |
| Persistent storage | âŒ | âœ… |
| Progress tracking | Basic | Detailed |
| Production-ready | âŒ | âœ… |

**Recommendation**: Always use `phase1_modal_robust.py` for actual experiments!

---

## ğŸ“ Support

- **Modal Docs**: https://modal.com/docs
- **Issues**: Check checkpoint files for detailed error logs
- **Logs**: `modal app logs nic-phase1-robust`
